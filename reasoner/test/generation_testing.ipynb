{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import logging\n",
    "import networkx as nx\n",
    "\n",
    "def generate_candidates(X, strategy, max_candidates, target_rel, consolidate_sides=False, seed=0):\n",
    "    \"\"\" Generate candidate statements from an existing knowledge graph using a defined strategy.\n",
    "        Parameters\n",
    "        ----------\n",
    "        strategy: string\n",
    "            The candidates generation strategy.\n",
    "            - 'random_uniform' : generates N candidates (N <= max_candidates) based on a uniform random sampling of\n",
    "                head and tail entities.\n",
    "            - 'entity_frequency' : generates candidates by sampling entities with low frequency.\n",
    "            - 'graph_degree' : generates candidates by sampling entities with a low graph degree.\n",
    "            - 'cluster_coefficient' : generates candidates by sampling entities with a low clustering coefficient.\n",
    "            - 'cluster_triangles' : generates candidates by sampling entities with a low number of cluster triangles.\n",
    "            - 'cluster_squares' : generates candidates by sampling entities with a low number of cluster squares.\n",
    "        max_candidates: int or float\n",
    "            The maximum numbers of candidates generated by 'strategy'.\n",
    "            Can be an absolute number or a percentage [0,1].\n",
    "            This does not guarantee the number of candidates generated.\n",
    "        target_rel : str\n",
    "            Target relation to focus on. The function will generate candidate\n",
    "             statements only with this specific relation type.\n",
    "        consolidate_sides: bool\n",
    "            If True will generate candidate statements as a product of\n",
    "            unique head and tail entities, otherwise will\n",
    "            consider head and tail entities separately. Default: False.\n",
    "        seed : int\n",
    "            Seed to use for reproducible results.\n",
    "        Returns\n",
    "        -------\n",
    "        X_candidates : ndarray, shape [n, 3]\n",
    "            A list of candidate statements.\n",
    "        Examples\n",
    "        --------\n",
    "        >>> import numpy as np\n",
    "        >>> from ampligraph.discovery.discovery import generate_candidates\n",
    "        >>>\n",
    "        >>> X = np.array([['a', 'y', 'b'],\n",
    "        >>>               ['b', 'y', 'a'],\n",
    "        >>>               ['a', 'y', 'c'],\n",
    "        >>>               ['c', 'y', 'a'],\n",
    "        >>>               ['a', 'y', 'd'],\n",
    "        >>>               ['c', 'y', 'd'],\n",
    "        >>>               ['b', 'y', 'c'],\n",
    "        >>>               ['f', 'y', 'e']])\n",
    "        >>> X_candidates = generate_candidates(X, strategy='graph_degree', target_rel='y', max_candidates=3)\n",
    "        >>> ([['a', 'y', 'e'],\n",
    "        >>>  ['f', 'y', 'a'],\n",
    "        >>>  ['c', 'y', 'e']])\n",
    "    \"\"\"\n",
    "\n",
    "    if strategy not in ['random_uniform', 'entity_frequency',\n",
    "                        'graph_degree', 'cluster_coefficient',\n",
    "                        'cluster_triangles', 'cluster_squares']:\n",
    "        msg = '%s is not a valid candidate generation strategy.' % strategy\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    if target_rel not in np.unique(X[:, 1]):\n",
    "        # No error as may be case where target_rel is not in X\n",
    "        msg = 'Target relation is not found in triples.'\n",
    "        logger.warning(msg)\n",
    "\n",
    "    if not isinstance(max_candidates, (float, int)):\n",
    "        msg = 'Parameter max_candidates must be a float or int.'\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    if max_candidates <= 0:\n",
    "        msg = 'Parameter max_candidates must be a positive integer ' \\\n",
    "              'or float in range (0,1].'\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    if isinstance(max_candidates, float):\n",
    "        max_candidates = int(max_candidates * len(X))\n",
    "\n",
    "    def _filter_candidates(X_candidates, X, remove_reflexive=True):\n",
    "        \"\"\" Inner function to filter candidate statements from X_candidates that are in X.\n",
    "        \"\"\"\n",
    "        X_candidates = _setdiff2d(X_candidates, X)\n",
    "        # Filter statements that are ['x', rel, 'x']\n",
    "        if remove_reflexive:\n",
    "            keep_idx = np.where(X_candidates[:, 0] != X_candidates[:, 2])\n",
    "            X_candidates = X_candidates[keep_idx]\n",
    "\n",
    "        return X_candidates\n",
    "\n",
    "    # Set random seed\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Get entities linked with this relation\n",
    "    if consolidate_sides:\n",
    "        e_s = np.unique(np.concatenate((X[:, 0], X[:, 2])))\n",
    "        e_o = e_s\n",
    "    else:\n",
    "        e_s = np.unique(X[:, 0])\n",
    "        e_o = np.unique(X[:, 2])\n",
    "\n",
    "    logger.info('Generating candidates using {} strategy.'.format(strategy))\n",
    "\n",
    "    if strategy == 'random_uniform':\n",
    "\n",
    "        # Take close to sqrt of max_candidates so that: len(meshgrid result) == max_candidates\n",
    "        sample_size = int(np.sqrt(max_candidates) + 10)  # +10 to allow for reduction in sampled array due to filtering\n",
    "\n",
    "        X_candidates = np.zeros([max_candidates, 3], dtype=object)  # Pre-allocate X_candidates array\n",
    "        num_retries, max_retries = 0, 5  # Retry up to 5 times to reach max_candidates\n",
    "        start_idx, end_idx = 0, 0  #\n",
    "        print(e_s)\n",
    "        while end_idx <= max_candidates - 1:\n",
    "            sample_e_s = np.random.choice(e_s, size=sample_size, replace=True)\n",
    "            sample_e_o = np.random.choice(e_o, size=sample_size, replace=True)\n",
    "\n",
    "            gen_candidates = np.array(np.meshgrid(sample_e_s, target_rel, sample_e_o)).T.reshape(-1, 3)\n",
    "            gen_candidates = _filter_candidates(gen_candidates, X)\n",
    "\n",
    "            # Select either all of gen_candidates or just enough to fill X_candidates\n",
    "            select_idx = min(len(gen_candidates), len(X_candidates) - start_idx)\n",
    "            end_idx = start_idx + select_idx\n",
    "\n",
    "            X_candidates[start_idx:end_idx, :] = gen_candidates[0:select_idx, :]\n",
    "            start_idx = end_idx\n",
    "\n",
    "            num_retries += 1\n",
    "            if num_retries == max_retries:\n",
    "                break\n",
    "\n",
    "        # end_idx will equal max_candidates in most cases, but could be less\n",
    "        return X_candidates[0:end_idx, :]\n",
    "\n",
    "    elif strategy == 'entity_frequency':\n",
    "\n",
    "        # Get entity counts and sort them in ascending order\n",
    "        if consolidate_sides:\n",
    "            e_s_counts = np.array(np.unique(X[:, [0, 2]], return_counts=True)).T\n",
    "            e_o_counts = e_s_counts\n",
    "        else:\n",
    "            e_s_counts = np.array(np.unique(X[:, 0], return_counts=True)).T\n",
    "            e_o_counts = np.array(np.unique(X[:, 2], return_counts=True)).T\n",
    "\n",
    "        e_s_weights = e_s_counts[:, 1].astype(np.float64) / np.sum(e_s_counts[:, 1].astype(np.float64))\n",
    "        e_o_weights = e_o_counts[:, 1].astype(np.float64) / np.sum(e_o_counts[:, 1].astype(np.float64))\n",
    "\n",
    "    elif strategy in ['graph_degree', 'cluster_coefficient', 'cluster_triangles', 'cluster_squares']:\n",
    "\n",
    "        # Create networkx graph\n",
    "        G = nx.Graph()\n",
    "        for row in X:\n",
    "            G.add_nodes_from([row[0], row[2]])\n",
    "            G.add_edge(row[0], row[2], name=row[1])\n",
    "\n",
    "        # Calculate node metrics\n",
    "        if strategy == 'graph_degree':\n",
    "            C = {i: j for i, j in G.degree()}\n",
    "        elif strategy == 'cluster_coefficient':\n",
    "            C = nx.algorithms.cluster.clustering(G)\n",
    "        elif strategy == 'cluster_triangles':\n",
    "            C = nx.algorithms.cluster.triangles(G)\n",
    "        elif strategy == 'cluster_squares':\n",
    "            C = nx.algorithms.cluster.square_clustering(G)\n",
    "\n",
    "        e_s_weights = np.array([C[x] for x in e_s], dtype=np.float64)\n",
    "        e_o_weights = np.array([C[x] for x in e_o], dtype=np.float64)\n",
    "\n",
    "        e_s_weights = e_s_weights / np.sum(e_s_weights)\n",
    "        e_o_weights = e_o_weights / np.sum(e_o_weights)\n",
    "\n",
    "    # Take close to sqrt of max_candidates so that: len(meshgrid result) == max_candidates\n",
    "    sample_size = int(np.sqrt(max_candidates) + 10)  # +10 to allow for reduction in sampled array due to filtering\n",
    "\n",
    "    X_candidates = np.zeros([max_candidates, 3], dtype=object)  # Pre-allocate X_candidates array\n",
    "    num_retries, max_retries = 0, 5  # Retry up to 5 times to reach max_candidates\n",
    "    start_idx, end_idx = 0, 0\n",
    "\n",
    "    while end_idx <= max_candidates - 1:\n",
    "\n",
    "        sample_e_s = np.random.choice(e_s, size=sample_size, replace=True, p=e_s_weights)\n",
    "        sample_e_o = np.random.choice(e_o, size=sample_size, replace=True, p=e_o_weights)\n",
    "\n",
    "        gen_candidates = np.array(np.meshgrid(sample_e_s, target_rel, sample_e_o)).T.reshape(-1, 3)\n",
    "        gen_candidates = _filter_candidates(gen_candidates, X)\n",
    "\n",
    "        # Select either all of gen_candidates or just enough to fill X_candidates\n",
    "        select_idx = min(len(gen_candidates), len(X_candidates) - start_idx)\n",
    "        end_idx = start_idx + select_idx\n",
    "\n",
    "        X_candidates[start_idx:end_idx, :] = gen_candidates[0:select_idx, :]\n",
    "        start_idx = end_idx\n",
    "\n",
    "        num_retries += 1\n",
    "\n",
    "        if num_retries == max_retries:\n",
    "            break\n",
    "\n",
    "    # end_idx will be max_candidates in most cases, but could be less\n",
    "    return X_candidates[0:end_idx, :]\n",
    "    \n",
    "def _setdiff2d(A, B):\n",
    "    \"\"\" Utility function equivalent to numpy.setdiff1d on 2d arrays.\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : ndarray, shape [n, m]\n",
    "    B : ndarray, shape [n, m]\n",
    "    Returns\n",
    "    -------\n",
    "    np.array, shape [k, m]\n",
    "        Rows of A that are not in B.\n",
    "    \"\"\"\n",
    "\n",
    "    if len(A.shape) != 2 or len(B.shape) != 2:\n",
    "        raise RuntimeError('Input arrays must be 2-dimensional.')\n",
    "\n",
    "    tmp = np.prod(np.swapaxes(A[:, :, None], 1, 2) == B, axis=2)\n",
    "    return A[~ np.sum(np.cumsum(tmp, axis=0) * tmp == 1, axis=1).astype(bool)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0', '0', '1'],\n",
       "       ['1', '0', '2'],\n",
       "       ['3', '1', '4'],\n",
       "       ['3', '2', '0'],\n",
       "       ['5', '3', '6'],\n",
       "       ['5', '4', '6'],\n",
       "       ['7', '5', '8'],\n",
       "       ['9', '6', '10']], dtype='<U2')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _read_triple(file_path):\n",
    "    triples = []\n",
    "    with open(file_path) as fin:\n",
    "        for line in fin:\n",
    "            h, r, t = line.strip().split('\\t')\n",
    "            triples.append((h, r, t))\n",
    "    return np.array(triples)\n",
    "\n",
    "X = _read_triple(\"/Users/karel/Documents/Master/Thesis/Combining-Machine-Learning-with-Reasoning/github/kge-reasoning/reasoner/test/sample/train.del\")\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_tmp = np.empty([1, 3], dtype=np.int) \n",
    "\n",
    "for relation in np.unique(X[:,1]):\n",
    "    X_candidates = generate_candidates(X, strategy='graph_degree', target_rel=relation, max_candidates=1., seed=0, consolidate_sides=False)\n",
    "    if relation == np.unique(X[:,1])[0]:\n",
    "        X_candidates_np = np.unique(np.array(X_candidates, dtype=np.int), axis=0)\n",
    "        continue\n",
    "    arr_tmp = X_candidates_np\n",
    "    X_candidates_np = np.unique(np.array(X_candidates, dtype=np.int), axis=0)\n",
    "    X_candidates_np = np.concatenate((X_candidates_np, arr_tmp), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 6, 2],\n",
       "       [3, 6, 2],\n",
       "       [5, 6, 2],\n",
       "       [9, 6, 2],\n",
       "       [1, 5, 2],\n",
       "       [3, 5, 2],\n",
       "       [5, 5, 2],\n",
       "       [9, 5, 2],\n",
       "       [1, 4, 2],\n",
       "       [3, 4, 2],\n",
       "       [5, 4, 2],\n",
       "       [9, 4, 2],\n",
       "       [1, 3, 2],\n",
       "       [3, 3, 2],\n",
       "       [5, 3, 2],\n",
       "       [9, 3, 2],\n",
       "       [1, 2, 2],\n",
       "       [3, 2, 2],\n",
       "       [5, 2, 2],\n",
       "       [9, 2, 2],\n",
       "       [1, 1, 2],\n",
       "       [3, 1, 2],\n",
       "       [5, 1, 2],\n",
       "       [9, 1, 2],\n",
       "       [1, 0, 2],\n",
       "       [3, 0, 2],\n",
       "       [5, 0, 2],\n",
       "       [9, 0, 2]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_candidates_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a5bb34bffb12c49171c6b9bf7f67eeb6f0b169a0a68257c4a256d0a5c373a53"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
